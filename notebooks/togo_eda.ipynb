{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8837dff6",
   "metadata": {},
   "source": [
    "Import The Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74d616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from windrose import WindroseAxes\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634185d8",
   "metadata": {},
   "source": [
    "Load The Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the raw dataset to start fresh\n",
    "df = pd.read_csv('../data/raw/togo-dapaong_qc.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae5edb",
   "metadata": {},
   "source": [
    "initial explaratory data analaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34a4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First 10 rows of raw data:\")\n",
    "print(df[['GHI', 'DNI', 'DHI']].head(10))\n",
    "\n",
    "print(\"\\nRandom sample of 10 rows:\")\n",
    "print(df[['GHI', 'DNI', 'DHI']].sample(10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b64b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rows do we actually have?\n",
    "print(\"Data shape:\", df.shape)\n",
    "\n",
    "# Show summary of selected columns\n",
    "print(df[['GHI', 'DNI', 'DHI', 'Tamb', 'WS']].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83559253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many rows have negative values for each column\n",
    "for col in ['GHI', 'DNI', 'DHI']:\n",
    "    negative_count = len(df[df[col] < 0])\n",
    "    print(f\"Number of rows with {col} < 0: {negative_count} ({negative_count / len(df) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c70fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics of all numeric columns\n",
    "summary_stats = df.describe()\n",
    "display(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3354500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values count per column\n",
    "missing_values = df.isna().sum()\n",
    "display(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9a16a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with more than 5% missing values\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "cols_over_5pct_null = missing_percent[missing_percent > 5]\n",
    "print(\"Columns with >5% missing values:\")\n",
    "print(cols_over_5pct_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e90dae",
   "metadata": {},
   "source": [
    "step-3 Pre-Proccesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with more than 5% missing values\n",
    "df = df.drop(columns=[\"Comments\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce17ff",
   "metadata": {},
   "source": [
    "set nagative values to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8f8a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "irr_cols = ['GHI', 'DNI', 'DHI']\n",
    "for col in irr_cols:\n",
    "    df[col] = df[col].clip(lower=0)  # Set negative values to 0\n",
    "    print(f\"After clipping, number of rows with {col} < 0: {len(df[df[col] < 0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a394a685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Timestamp to datetime and set as index\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df = df.set_index('Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28690557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Set up a grid for plots\n",
    "cols_to_check = ['GHI', 'DNI', 'DHI', 'Tamb', 'WS']\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "for i, col in enumerate(cols_to_check):\n",
    "    plt.subplot(2, 3, i + 1)\n",
    "    sns.histplot(df[col], bins=50, kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e145d6f8",
   "metadata": {},
   "source": [
    "Next Step: Outlier Detection & Basic Cleaning (Detailed)\n",
    "Objective: Detect outliers using Z-scores (|Z| > 3) and handle them \n",
    "\n",
    "Plan:\n",
    "\n",
    "Compute Z-scores for GHI, DNI, DHI, ModA, ModB, WS, and WSgust.\n",
    "Flag rows with |Z| > 3 as outliers.\n",
    "Impute outliers with the median value of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e680d181",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define key columns for outlier detection\n",
    "key_cols = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "\n",
    "# Detect and handle outliers using Z-scores\n",
    "for col in key_cols:\n",
    "    if col in df.columns:\n",
    "        # Calculate Z-scores, ignoring NaN\n",
    "        z_scores = stats.zscore(df[col].dropna())\n",
    "        # Create a mask for outliers (|Z| > 3)\n",
    "        outlier_mask = abs(z_scores) > 3\n",
    "        # Get the original indices of outliers\n",
    "        outlier_indices = df.index[np.where(outlier_mask)[0]]\n",
    "        print(f\"Number of outliers for {col}: {len(outlier_indices)}\")\n",
    "        # Impute outliers with the median (only for non-NaN values)\n",
    "        df.loc[outlier_indices, col] = df[col].median()\n",
    "\n",
    "# Verify the shape and summary statistics after outlier handling\n",
    "print(\"\\nData shape after outlier handling:\", df.shape)\n",
    "print(\"\\nSummary Statistics after outlier handling:\")\n",
    "print(df[['GHI', 'DNI', 'DHI', 'Tamb', 'WS']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef5ce3",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555dfae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# How many rows do we actually have?\n",
    "print(\"Data shape:\", df.shape)\n",
    "\n",
    "# Show summary of selected columns\n",
    "print(df[['GHI', 'DNI', 'DHI', 'Tamb', 'WS']].describe())\n",
    "\n",
    "\n",
    "\n",
    "# Summary statistics of all numeric columns\n",
    "summary_stats = df.describe()\n",
    "display(summary_stats)\n",
    "# Check how many rows have negative values for each column\n",
    "for col in ['GHI', 'DNI', 'DHI']:\n",
    "    negative_count = len(df[df[col] < 0])\n",
    "    print(f\"Number of rows with {col} < 0: {negative_count} ({negative_count / len(df) * 100:.2f}%)\")\n",
    "\n",
    "# Check data types\n",
    "print(\"\\nChecking Column Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Missing values count per column\n",
    "missing_values = df.isna().sum()\n",
    "display(missing_values)\n",
    "\n",
    "# Summary of categorical columns (text output)\n",
    "print(\"\\nSummary of categorical columns\\n\")\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_columns:\n",
    "    print(f\"Value Counts of {col}:\")\n",
    "    print(df[col].value_counts())\n",
    "\n",
    "# Columns with more than 5% missing values\n",
    "missing_percent = (missing_values / len(df)) * 100\n",
    "cols_over_5pct_null = missing_percent[missing_percent > 5]\n",
    "print(\"Columns with >5% missing values:\")\n",
    "print(cols_over_5pct_null)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9481e1",
   "metadata": {},
   "source": [
    "\n",
    "Visualization\n",
    "\n",
    "Next Step: Time Series Analysis\n",
    "Objective: Perform time series analysis on GHI, DNI, DHI, and Tamb to observe patterns \n",
    "\n",
    "Plan:\n",
    "Plot line charts for GHI, DNI, DHI, and Tamb over time.\n",
    " Analyze patterns by month and hour.\n",
    " Identify anomalies (e.g., unexpected peaks in GHI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb1bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot line charts for GHI, DNI, DHI, and Tamb over time\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot GHI\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(df.index, df['GHI'], label='GHI', color='blue')\n",
    "plt.title('GHI over Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('GHI (W/m²)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot DNI\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(df.index, df['DNI'], label='DNI', color='orange')\n",
    "plt.title('DNI over Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('DNI (W/m²)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot DHI\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(df.index, df['DHI'], label='DHI', color='green')\n",
    "plt.title('DHI over Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('DHI (W/m²)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot Tamb\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(df.index, df['Tamb'], label='Tamb', color='red')\n",
    "plt.title('Tamb over Time')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Tamb (°C)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Adjust layout to avoid overlap\n",
    "plt.tight_layout()\n",
    "plt.savefig('notebooks/togo/timeseries_plots.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8a9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patterns by month\n",
    "monthly_avg = df.groupby(df.index.month)[['GHI', 'DNI', 'DHI', 'Tamb']].mean()\n",
    "print(\"Monthly Averages:\\n\", monthly_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b67ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze patterns by hour of the day\n",
    "hourly_avg = df.groupby(df.index.hour)[['GHI', 'DNI', 'DHI']].mean()\n",
    "print(\"\\nHourly Averages:\\n\", hourly_avg)\n",
    "\n",
    "# Look for anomalies (e.g., GHI spikes)\n",
    "ghi_spikes = df[df['GHI'] > df['GHI'].quantile(0.99)]  # Top 1% of GHI values\n",
    "print(\"\\nPotential GHI Anomalies (Spikes):\\n\", ghi_spikes[['GHI']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc86b967",
   "metadata": {},
   "source": [
    " Next Step: Cleaning Impact Analysis\n",
    " Objective: Analyze the impact of the Cleaning flag on ModA and ModB, \n",
    "\n",
    " Plan:\n",
    "\n",
    " Group the data by the Cleaning flag.\n",
    " Compute the mean of ModA and ModB for each group (pre- and post-cleaning).\n",
    " Plot a bar chart to compare the averages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c791b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Group by Cleaning flag and calculate mean for ModA and ModB\n",
    "cleaning_impact = df.groupby('Cleaning')[['ModA', 'ModB']].mean()\n",
    "print(\"Average ModA and ModB by Cleaning Flag:\\n\", cleaning_impact)\n",
    "\n",
    "# Plot the impact of cleaning on ModA and ModB\n",
    "cleaning_impact_melted = cleaning_impact.reset_index().melt(id_vars='Cleaning', value_vars=['ModA', 'ModB'], var_name='Module', value_name='Value')\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x='Cleaning', y='Value', hue='Module', data=cleaning_impact_melted)\n",
    "plt.title('Impact of Cleaning on ModA and ModB')\n",
    "plt.xlabel('Cleaning Flag (0 = Before, 1 = After)')\n",
    "plt.ylabel('Average Value (W/m²)')\n",
    "plt.savefig('notebooks/togo/cleaning_impact_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198bf636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next Step: Correlation Analysis\n",
    "# Objective: Compute the correlation matrix for GHI, DNI, DHI, Tamb, WS, ModA, and ModB to identify relationships, as specified in Task 2. Visualize the correlations using a heatmap.\n",
    "\n",
    "# Plan:\n",
    "\n",
    "# Calculate the Pearson correlation matrix for the specified columns.\n",
    "# Create a heatmap to visualize the correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0df914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns for correlation analysis\n",
    "correlation_cols = ['GHI', 'DNI', 'DHI', 'Tamb', 'WS', 'ModA', 'ModB']\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = df[correlation_cols].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0)\n",
    "plt.title('Correlation Matrix of Solar Variables')\n",
    "plt.savefig('notebooks/togo/correlation_heatmap.png')\n",
    "plt.show()\n",
    "\n",
    "print(\"Correlation Matrix:\\n\", correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32abb5bd",
   "metadata": {},
   "source": [
    "Next Step: Wind Rose Plot\n",
    " Objective: Create a wind rose or radial bar plot to visualize the distribution of wind speed (WS) and wind direction (WD),\n",
    "\n",
    " Plan:\n",
    "\n",
    " Use the windrose library to plot WS against WD.\n",
    " Ensure WD is in degrees (0–360) and WS is in m/s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e095a557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create wind rose plot\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = WindroseAxes.from_ax(fig=fig)\n",
    "ax.bar(df['WD'], df['WS'], normed=True, opening=0.8, edgecolor='white')\n",
    "ax.set_legend(title=\"Wind Speed (m/s)\")\n",
    "plt.title('Wind Rose Plot')\n",
    "\n",
    "# Create notebooks directory if it doesn't exist\n",
    "os.makedirs('notebooks', exist_ok=True)\n",
    "plt.savefig('notebooks/togo/wind_rose_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to a CSV file\n",
    "df.to_csv('../data/cleaned/togo_cleaned.csv', index=True)\n",
    "print(\"Cleaned dataset saved to 'data/togo_cleaned.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
